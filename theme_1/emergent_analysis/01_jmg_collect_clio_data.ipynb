{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect and process data\n",
    "\n",
    "Closes issue #1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import seaborn as sn\n",
    "sys.path.append(os.path.abspath('../../'))\n",
    "#from query_indicators import generate_save_path\n",
    "from query_indicators import get_notebook_name\n",
    "from query_indicators import get_eu_countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from collections import defaultdict\n",
    "from clio_lite import clio_search, clio_search_iter\n",
    "import io\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.collections import PatchCollection\n",
    "from matplotlib.patches import Rectangle\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some globals\n",
    "URL = \"https://search-eurito-prod-bbyn72q2rhx4ifj6h5dom43uhy.eu-west-1.es.amazonaws.com/\"\n",
    "#INDEX = \"arxiv_v0\" \n",
    "FIELDS = ['terms_tokens_entity', 'textBody_abstract_article']\n",
    "EU_COUNTRIES = get_eu_countries() \n",
    "#fix: the above API produces erroneous list, so we clean it below\n",
    "EU_COUNTRIES = [e for e in EU_COUNTRIES if e not in (\"AX\", \"FO\", \"GF\", \"GI\", \"IM\")]\n",
    "COLORS = plt.get_cmap('Set2').colors\n",
    "COLOR_MAP = 'Pastel1'\n",
    "S3 = boto3.resource('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emergent_search(query, max_query_terms,index, fields,yr0=2014, yr1=2019,countries=EU_COUNTRIES, window=1):\n",
    "    \"\"\"\n",
    "    Retrieve count and score data for a given basic clio search.\n",
    "    \n",
    "    Args:\n",
    "        query (str): Seed query for clio.\n",
    "        max_query_terms (list): Triple of max_query_terms (low, middle, high) to use from the initial query.\n",
    "        yr0 (int): Start year in range to use in filter.\n",
    "        yr1 (int): Final year in range to use in filter.\n",
    "        countries (list): A list of countries to filter (default to all EU).\n",
    "        window (int): The number of years to consider in between time windows. Note that changing this will lead to double-counting.\n",
    "    Returns:\n",
    "        results: list with data\n",
    "    \"\"\"\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    print(f'running {query}')\n",
    "    \n",
    "    for n in max_query_terms:\n",
    "        # Iterate over years\n",
    "        for yr in range(yr0, yr1+1):       \n",
    "            # Iterate over docs\n",
    "            filters = [{\"range\":{\"year_of_article\":{\"gte\":yr, \"lt\":yr+window}}}]\n",
    "            for doc in clio_search_iter(url=URL, index=index, query=query, fields=fields,\n",
    "                                        max_query_terms=n, post_filters=filters, chunksize=5000):\n",
    "                \n",
    "                #We add the query sources\n",
    "                doc['max_query_terms'] = n\n",
    "                doc['query_source'] = query\n",
    "                \n",
    "                if '_score' not in doc or doc['terms_countries_article'] is None:\n",
    "                    continue\n",
    "                else:\n",
    "                    results.append(doc)\n",
    "    return(results)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ArXiv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running artificial intelligence\n",
      "running intelligent system\n",
      "running expert system\n",
      "running machine learning\n",
      "running neural network\n",
      "running deep learning\n",
      "running reinforcement learning\n"
     ]
    }
   ],
   "source": [
    "ai_results = [emergent_search(var,[3,10,15],yr0=2000,yr1=2019,index='arxiv_v0',\n",
    "                              fields=['terms_tokens_entity', 'textBody_abstract_article']) \n",
    "              for var in ['artificial intelligence','intelligent system','expert system',\n",
    "                          'machine learning','neural network','deep learning', 'reinforcement learning']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artificial_intelligence\n",
      "intelligent_system\n",
      "expert_system\n",
      "machine_learning\n",
      "neural_network\n",
      "deep_learning\n",
      "reinforcement_learning\n"
     ]
    }
   ],
   "source": [
    "#Serialise results\n",
    "\n",
    "queries = ['artificial intelligence','intelligent system','expert system',\n",
    "                          'machine learning','neural network','deep learning', 'reinforcement learning']\n",
    "\n",
    "for x,name in zip(ai_results,queries):\n",
    "    \n",
    "    clean_name = '_'.join(name.split(' '))\n",
    "    \n",
    "    print(clean_name)\n",
    "    \n",
    "    with open(f'../../data/ai_results/{clean_name}.p','wb') as outfile:\n",
    "        pickle.dump(x,outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sectoral data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running health medical\n",
      "running climate environment\n",
      "running manufacturing factory\n",
      "running finance market\n"
     ]
    }
   ],
   "source": [
    "sector_results = [emergent_search(var,[1,2,5],yr0=2010,yr1=2019,index='arxiv_v0',\n",
    "                              fields=['terms_tokens_entity', 'textBody_abstract_article']) \n",
    "              for var in ['health medical','climate environment','manufacturing factory','finance market']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14553, 5016, 5319, 6954]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(x) for x in sector_results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
