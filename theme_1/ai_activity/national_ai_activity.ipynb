{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath('../../'))\n",
    "from query_indicators import generate_save_path\n",
    "from query_indicators import get_eu_countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from collections import defaultdict\n",
    "from clio_lite import clio_search, clio_search_iter\n",
    "import io\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.collections import PatchCollection\n",
    "from matplotlib.patches import Rectangle\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Env variables\n",
    "mpl.rcParams['hatch.linewidth'] = 0.2\n",
    "mpl.rcParams['font.size'] = 18\n",
    "mpl.rcParams['image.cmap'] = 'Pastel1'\n",
    "os.environ['AWS_SHARED_CREDENTIALS_FILE'] = '/Users/jklinger/EURITO-AWS/.aws/credentials'  # <--- Note: NOT nesta's AWS credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some globals\n",
    "URL = \"https://search-eurito-dev-vq22tw6otqjpdh47u75bh2g7ba.eu-west-2.es.amazonaws.com/\"\n",
    "INDEX = \"arxiv_v0\" \n",
    "FIELDS = ['terms_tokens_entity', 'textBody_abstract_article']\n",
    "EU_COUNTRIES = get_eu_countries()\n",
    "COLORS = plt.get_cmap('Set2').colors\n",
    "COLOR_MAP = 'Pastel1'\n",
    "S3 = boto3.resource('s3')\n",
    "SAVE_PATH = generate_save_path()  # EURITO collaborators: this is generated assuming you have stuck to the convention 'theme_x/something/something_else.ipynb'\n",
    "BUCKET = 'eurito-indicators'  # EURITO collaborators: please don't change this\n",
    "SAVE_RESULTS = True  # Set this to \"False\" when you want to view figures inline. When \"True\", results will be saved to S3.\n",
    "\n",
    "if SAVE_RESULTS:\n",
    "    plt.ioff()  # <--- for turning off visible figs\n",
    "else:\n",
    "    plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_search(query, max_query_terms, yr0=2014, yr1=2019, countries=EU_COUNTRIES, window=1):\n",
    "    \"\"\"\n",
    "    Retrieve count and score data for a given basic clio search.\n",
    "    \n",
    "    Args:\n",
    "        query (str): Seed query for clio.\n",
    "        max_query_terms (list): Triple of max_query_terms (low, middle, high) to use from the initial query.\n",
    "        yr0 (int): Start year in range to use in filter.\n",
    "        yr1 (int): Final year in range to use in filter.\n",
    "        countries (list): A list of countries to filter (default to all EU).\n",
    "        window (int): The number of years to consider in between time windows. Note that changing this will lead to double-counting.\n",
    "    Returns:\n",
    "        data (dict): {max_query_terms --> [{year --> sum_score} for each country]}\n",
    "        all_scores (dict): {max_query_terms --> {country --> [score for doc in docs] } }\n",
    "    \"\"\"\n",
    "    top_doc = None\n",
    "    _data = defaultdict(lambda: defaultdict(dict))  # {max_query_terms --> {year --> {country --> score} } }\n",
    "    all_scores = defaultdict(lambda: defaultdict(list))  # {max_query_terms --> {country --> [score for doc in docs] } }\n",
    "    for n in max_query_terms:\n",
    "        # Set the order of the countries\n",
    "        for ctry in EU_COUNTRIES:\n",
    "            _data[n][ctry]\n",
    "            all_scores[n][ctry]\n",
    "        # Iterate over years\n",
    "        for yr in range(yr0, yr1+1):\n",
    "            # Set default values for countries\n",
    "            for ctry in EU_COUNTRIES:\n",
    "                _data[n][ctry][yr] = 0            \n",
    "            # Iterate over docs\n",
    "            filters = [{\"range\":{\"year_of_article\":{\"gte\":yr, \"lt\":yr+window}}}]\n",
    "            for doc in clio_search_iter(url=URL, index=INDEX, query=query, fields=FIELDS,\n",
    "                                        max_query_terms=n, post_filters=filters, chunksize=5000):\n",
    "                if '_score' not in doc or doc['terms_countries_article'] is None:\n",
    "                    continue\n",
    "                score = doc['_score']\n",
    "                for ctry in filter(lambda x: x in countries, doc['terms_countries_article']):\n",
    "                    if top_doc is None:\n",
    "                        top_doc = doc                \n",
    "                    all_scores[n][ctry].append(score)\n",
    "                    _data[n][ctry][yr] += score\n",
    "    # Reformat data as {max_query_terms --> [{year --> score} for each country in order]}\n",
    "    data = {}\n",
    "    for n, ctry_data in _data.items():\n",
    "        data[n] = []\n",
    "        for ctry, yr_data in ctry_data.items():\n",
    "            data[n].append(yr_data)\n",
    "    return top_doc, data, all_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indicator calculations\n",
    "\n",
    "Each of these functions is assumed to take the form\n",
    "\n",
    "```python\n",
    "def _an_indicator_calulation(data, year=None, _max=1):\n",
    "    \"\"\"\n",
    "    A function calculating an indicator.\n",
    "    \n",
    "    Args:\n",
    "        data (list): Rows of data\n",
    "        year (int): A year to consider, if applicable.\n",
    "        _max (int): Divide by this to normalise your results. This is automatically applied in :obj:`make_activity_plot`\n",
    "    Returns:\n",
    "        result (list) A list of indicators to plot. The length of the list is assumed to be equal to the number of countries.\n",
    "    \"\"\"\n",
    "    # Calculate something\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _total_activity_by_country(data, year=None, _max=1):\n",
    "    \"\"\"\n",
    "    Indicator: Sum of relevance scores, by year (if specified) or in total.\n",
    "    \"\"\"    \n",
    "    if year is None:        \n",
    "        scores = [sum(row.values())/_max for row in data]\n",
    "    else:\n",
    "        scores = [row[year]/_max for row in data]\n",
    "    return scores\n",
    "      \n",
    "\n",
    "def _average_activity_by_country(data, year=None, _max=1):    \n",
    "    \"\"\"\n",
    "    Indicator: Mean relevance score. This function is basically a lambda, since it assumes the average has already been calculated.\n",
    "    \"\"\"        \n",
    "    return [row/_max for row in data]\n",
    "    \n",
    "    \n",
    "def _corrected_average_activity_by_country(data, year=None, _max=1):\n",
    "    \"\"\"\n",
    "    Indicator: Mean relevance score minus it's (very) approximate Poisson error.\n",
    "    \"\"\"    \n",
    "    return [(row - np.sqrt(row))/_max for row in data]\n",
    "    \n",
    "\n",
    "def _linear_coeffs(years, scores, _max):\n",
    "    \"\"\"Calculates linear coefficients for scores wrt years\"\"\"\n",
    "    return [np.polyfit(_scores, _years, 1)[0]/_max\n",
    "            if all(v > 0 for v in _scores) else 0\n",
    "            for _years, _scores in zip(years, scores)]    \n",
    "    \n",
    "\n",
    "def _trajectory(data, year=None, _max=1):\n",
    "    \"\"\"\n",
    "    Indicator: Linear coefficient of total relevance score wrt year\n",
    "    \"\"\"\n",
    "    years = [list(row.keys()) for row in data]\n",
    "    scores = [list(row.values()) for row in data]\n",
    "    return _linear_coeffs(years, scores, _max)\n",
    "\n",
    "\n",
    "def _corrected_trajectory(data, year=None, _max=1):\n",
    "    \"\"\"\n",
    "    Indicator: Linear coefficient of upper and lower limits of relevance score wrt year\n",
    "    \"\"\" \n",
    "    # Reformulate the data in terms of upper and lower bounds\n",
    "    years, scores = [], []\n",
    "    for row in data:\n",
    "        _years, _scores = [], []\n",
    "        for k, v in row.items():\n",
    "            _years += [k,k]\n",
    "            _scores += [v - np.sqrt(v), v + np.sqrt(v)]  # Estimate upper and lower limits with very approximate Poisson errors\n",
    "        years.append(_years)\n",
    "        scores.append(_scores)\n",
    "    return _linear_coeffs(years, scores, _max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _Sorter:\n",
    "    def __init__(self, values, topn=None):\n",
    "        if topn is None:\n",
    "            topn = len(values)\n",
    "        self.indices = list(np.argsort(values))[-topn:]  # Argsort is ascending, so -ve indexing to pick up topn\n",
    "    def sort(self, x):\n",
    "        \"\"\"Sort list x by indices\"\"\"\n",
    "        return [x[i] for i in self.indices]\n",
    "\n",
    "\n",
    "def _s3_savefig(query, fig_name, extension='png'):\n",
    "    \"\"\"Save the figure to s3. The figure is grabbed from the global scope.\"\"\"\n",
    "    if not SAVE_RESULTS:\n",
    "        return    \n",
    "    outname = (f'figures/{SAVE_PATH}/'\n",
    "               f'{query.replace(\" \",\"_\").lower()}'\n",
    "               f'/{fig_name.replace(\" \",\"_\").lower()}'\n",
    "               f'.{extension}')\n",
    "    with io.BytesIO() as f:\n",
    "        plt.savefig(f, bbox_inches='tight', format=extension, pad_inches=0)\n",
    "        obj = S3.Object(BUCKET, outname)\n",
    "        f.seek(0)\n",
    "        obj.put(Body=f)\n",
    "\n",
    "        \n",
    "def _s3_savetable(data, key, index, object_path, transformer=lambda x: x):\n",
    "    \"\"\"Upload the table to s3\"\"\"\n",
    "    if not SAVE_RESULTS:\n",
    "        return\n",
    "    df = pd.DataFrame(transformer(data[key]), index=index)\n",
    "    if len(df.columns) == 1:\n",
    "        df.columns = ['value']\n",
    "    df = df / df.max().max()\n",
    "    table_data = df.to_csv().encode()\n",
    "    obj = S3.Object(BUCKET, os.path.join(f'tables/{SAVE_PATH}', object_path))\n",
    "    obj.put(Body=table_data)\n",
    "\n",
    "        \n",
    "def make_activity_plot(f, data, countries, max_query_terms, query, \n",
    "                       year=None, label=None, x_padding=0.5, y_padding=0.05, xlabel_fontsize=14):\n",
    "    \"\"\"\n",
    "    Make a query and generate indicators by country, saving the plots to S3 and saving the rawest data\n",
    "    to tables on S3.\n",
    "    \n",
    "    \n",
    "    Args:\n",
    "        f: An indicator function, as described in the 'Indicator calculations' section.\n",
    "        data (dict): {max_query_terms --> [{year --> sum_score} for each country]}\n",
    "        countries (list): A list of EU ISO-2 codes        \n",
    "        max_query_terms (list): Triple of max_query_terms for clio, corresponding to low, middle and high values of \n",
    "                                max_query_terms to test robustness of the query.\n",
    "        query (str): query used to generate this data.\n",
    "        year (int): Year to generate the indicator for (if applicable).\n",
    "        label (str): label for annotating the plot.\n",
    "        {x,y}_padding (float): Aesthetic padding around the extreme limits of the {x,y} axis.\n",
    "        xlabel_fontsize (int): Fontsize of the x labels (country ISO-2 codes).\n",
    "    \"\"\"    \n",
    "    # Calculate the indicator for each value of n, then recalculate the normalised indicator\n",
    "    _, middle, _ = (f(data[n], year=year) for n in max_query_terms)\n",
    "    low, middle, high = (f(data[n], year=year, _max=max(middle)) for n in max_query_terms)\n",
    "    indicator = [np.median([a, b, c]) for a, b, c in zip(low, middle, high)]    \n",
    "\n",
    "    # Sort all data by indicator value\n",
    "    s = _Sorter(indicator)\n",
    "    countries = s.sort(countries)\n",
    "    low = s.sort(low)\n",
    "    middle = s.sort(middle)\n",
    "    high =  s.sort(high)\n",
    "    indicator = s.sort(indicator)\n",
    "\n",
    "    # Make the scatter plot\n",
    "    fig, ax = plt.subplots(figsize=(15, 6))    \n",
    "    make_error_boxes(ax, low, middle, high)  # Draw the bounding box\n",
    "    ax.scatter(countries, indicator,  s=0, marker='o', color='black')  # Draw the centre mark\n",
    "    ax.set_title(f'{label}\\nQuery: \"{query}\"')\n",
    "    ax.set_ylabel(label)\n",
    "\n",
    "    # Set limits and formulate \n",
    "    y0 = min(low+middle+high)    \n",
    "    y1 = max(low+middle+high)\n",
    "    if -y1*y_padding < y0:\n",
    "        y0 = -y1*y_padding\n",
    "    else:  # In case of negative values\n",
    "        y0 = y0 - np.abs(y0*y_padding)\n",
    "    ax.set_ylim(y0, y1*(1+y_padding))\n",
    "    ax.set_xlim(-x_padding, len(countries)-x_padding)\n",
    "    for tick in ax.xaxis.get_major_ticks():\n",
    "        tick.label.set_fontsize(xlabel_fontsize)\n",
    "    \n",
    "    # Save to s3 & return\n",
    "    _s3_savefig(query, label)\n",
    "    return ax\n",
    "\n",
    "\n",
    "def make_error_boxes(ax, low, middle, high, facecolor='r',\n",
    "                     edgecolor='None', alpha=0.5):\n",
    "    \"\"\"\n",
    "    Generate outer rectangles based on three values, and draw a horizontal line through the middle of the rectangle.\n",
    "    No assumption is made on the order of values, so don't worry if they're not properly ordered.\n",
    "        \n",
    "    Args:\n",
    "        ax (matplotlib.axis): An axis to add patches to.\n",
    "        {low, middle, high} (list): Three concurrent lists of values from which to calculate the rectangle limits.\n",
    "        {facecolor, edgecolor} (str): The {face,edge} colour of the rectangles.\n",
    "        alpha (float): The alpha of the rectangles.\n",
    "    \"\"\"\n",
    "    # Generate the rectangle\n",
    "    errorboxes = []\n",
    "    middlelines = []\n",
    "    for x, ys in enumerate(zip(low, middle, high)):        \n",
    "        rect = Rectangle((x - 0.45, min(ys)), 0.9, max(ys) - min(ys))\n",
    "        line = Rectangle((x - 0.45, np.median(ys)), 0.9, 0)\n",
    "        errorboxes.append(rect)\n",
    "        middlelines.append(line)\n",
    "\n",
    "    # Create patch collection with specified colour/alpha\n",
    "    pc = PatchCollection(errorboxes, facecolor=facecolor, alpha=alpha, edgecolor=edgecolor, hatch='/')\n",
    "    lc = PatchCollection(middlelines, facecolor='black', alpha=0.9, edgecolor='black')\n",
    "\n",
    "    # Add collection to axes\n",
    "    ax.add_collection(pc)\n",
    "    ax.add_collection(lc)\n",
    "\n",
    "\n",
    "def stacked_scores(all_scores, query, topn=8,\n",
    "                   low_bins=[10**i for i in np.arange(0, 1.1, 0.025)],\n",
    "                   high_bins=[10**i for i in np.arange(1.1, 2.5, 0.05)],\n",
    "                   x_scale='log', label='Relevance score breakdown', \n",
    "                   xlabel='Relevance score', ylabel='Number of relevant documents',\n",
    "                   legend_fontsize='small', legend_cols=2):\n",
    "    \"\"\"\n",
    "    Create stacked histogram of document scores by country. Two sets of bins are used, \n",
    "    in order to have a more legible binning scale.\n",
    "    \n",
    "    Args:\n",
    "        all_scores (dict): {max_query_terms --> {country --> [score for doc in docs] } }\n",
    "        query (str): query used to generate this data.\n",
    "        low_bins (list): List of initial bin edges.\n",
    "        high_bins (list): List of supplementary bin edges. These could have a different spacing scheme to the lower bin edges.\n",
    "        x_scale (str): Argument for `ax.set_xscale`.\n",
    "        label (str): label for annotating the plot.\n",
    "        {x,y}_label (str): Argument for `ax.set_{x,y}label`.\n",
    "        legend_fontsize (str): Argument for legend fontsize.\n",
    "        legend_cols (str): Argument for legend ncol.        \n",
    "    \"\"\"\n",
    "    \n",
    "    # Sort countries and scores by the sum of scores by country\n",
    "    countries = list(all_scores.keys())\n",
    "    scores = list(all_scores.values())    \n",
    "    s = _Sorter([sum(v) for v in scores], topn=topn)\n",
    "    scores = s.sort(scores)\n",
    "    countries = s.sort(countries)\n",
    "\n",
    "    # Plot the stacked scores\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    plt.set_cmap(COLOR_MAP)\n",
    "    ax.hist(scores, bins=low_bins+high_bins, stacked=True,\n",
    "            label=countries, color=COLORS[:len(scores)])\n",
    "    \n",
    "    # Prettify the plot\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.legend(fontsize=legend_fontsize, ncol=legend_cols)\n",
    "    ax.set_xlim(low_bins[0], None)\n",
    "    ax.set_xscale(x_scale)\n",
    "    ax.set_title(f'{label}\\nQuery: \"{query}\"')\n",
    "    \n",
    "    # Save to s3\n",
    "    _s3_savefig(query, label)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bringing it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_indicator(q, max_query_terms=[7, 10, 13], countries=EU_COUNTRIES, *args, **kwargs):\n",
    "    \"\"\"\n",
    "    Make a query and generate indicators by country, saving the plots to S3 and saving the rawest data\n",
    "    to tables on S3.\n",
    "    \n",
    "    \n",
    "    Args:\n",
    "        q (str): The query to Elasticsearch\n",
    "        max_query_terms (list): Triple of max_query_terms for clio, corresponding to low, middle and high values of \n",
    "                                max_query_terms to test robustness of the query.\n",
    "        countries (list): A list of EU ISO-2 codes\n",
    "    Returns:\n",
    "        top_doc (dict): The highest ranking document from the search.\n",
    "        data (dict): {max_query_terms --> [{year --> sum_score} for each country]}\n",
    "        all_scores (dict): {max_query_terms --> {country --> [score for doc in docs] } }\n",
    "    \"\"\"\n",
    "    \n",
    "    # Make the search and retrieve scores by country, and the highest ranking doc\n",
    "    example_doc, data, all_scores = make_search(q, max_query_terms=max_query_terms, countries=countries, *args, **kwargs)\n",
    "\n",
    "    # Reformat the scores to calculate the average\n",
    "    avg_scores = defaultdict(list)\n",
    "    for ctry in countries:\n",
    "        for n, _scores in all_scores.items():\n",
    "            mean = np.mean(_scores[ctry]) if len(_scores[ctry]) > 0 else 0\n",
    "            avg_scores[n].append(mean)\n",
    "    \n",
    "    plot_kwargs = dict(countries=countries, max_query_terms=max_query_terms, query=q)\n",
    "    # Calculate loads of indicators and save the plots\n",
    "    _ = make_activity_plot(_total_activity_by_country, data, label='Total relevance score', **plot_kwargs)\n",
    "    _ = make_activity_plot(_average_activity_by_country, avg_scores, label='Average relevance', **plot_kwargs)\n",
    "    _ = make_activity_plot(_corrected_average_activity_by_country, avg_scores, label='Corrected average relevance',  **plot_kwargs)\n",
    "    _ = make_activity_plot(_trajectory, data, label='Trajectory', **plot_kwargs)\n",
    "    _ = make_activity_plot(_corrected_trajectory, data, label='Corrected trajectory', **plot_kwargs)\n",
    "    _ = stacked_scores(all_scores[max_query_terms[1]], query=q)\n",
    "    \n",
    "    # Save the basic raw data as tables. Note: not as rich as the plotted data.\n",
    "    _q = q.replace(\" \",\"_\").lower()\n",
    "    _s3_savetable(data, max_query_terms[1], index=countries, object_path=f'{_q}/total_relevance.csv')\n",
    "    _s3_savetable(avg_scores, max_query_terms[1], index=countries, object_path=f'{_q}/avg_relevance.csv')\n",
    "    _s3_savetable(data, max_query_terms[1], transformer=_trajectory, index=countries, object_path=f'{_q}/trajectory.csv')\n",
    "    \n",
    "    plt.close('all')  # Clean up the memory cache (unbelievable that matplotlib doesn't do this)\n",
    "    return example_doc, data, all_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterate over queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural Language Generation\n",
      "---------------------------\n",
      "A Deep Architecture for Semantic Parsing , 2014\n",
      "['CA', 'GB']\n",
      "Many successful approaches to semantic parsing build on top of the syntactic\n",
      "analysis of text, and make use of distributional representations or statistical\n",
      "models to match parses to ontology-specific queries. This paper presents a\n",
      "novel deep learning architecture which provides a semantic parsing system\n",
      "through the union of two neural models of language semantics. It allows for the\n",
      "generation of ontology-specific queries from natural language statements and\n",
      "questions without the need for parsing, which makes it especially suitable to\n",
      "grammatically malformed or syntactically atypical text, such as tweets, as well\n",
      "as permitting the development of semantic parsers for resource-poor languages.\n",
      "\n",
      "==============================\n",
      "\n",
      "Speech recognition\n",
      "------------------\n",
      "Spatial Diffuseness Features for DNN-Based Speech Recognition in Noisy\n",
      "  and Reverberant Environments , 2014\n",
      "['DE']\n",
      "We propose a spatial diffuseness feature for deep neural network (DNN)-based\n",
      "automatic speech recognition to improve recognition accuracy in reverberant and\n",
      "noisy environments. The feature is computed in real-time from multiple\n",
      "microphone signals without requiring knowledge or estimation of the direction\n",
      "of arrival, and represents the relative amount of diffuse noise in each time\n",
      "and frequency bin. It is shown that using the diffuseness feature as an\n",
      "additional input to a DNN-based acoustic model leads to a reduced word error\n",
      "rate for the REVERB challenge corpus, both compared to logmelspec features\n",
      "extracted from noisy signals, and features enhanced by spectral subtraction.\n",
      "\n",
      "==============================\n",
      "\n",
      "Virtual Agents\n",
      "--------------\n",
      "Expressing social attitudes in virtual agents for social training games , 2014\n",
      "['FR']\n",
      "The use of virtual agents in social coaching has increased rapidly in the\n",
      "last decade. In order to train the user in different situations than can occur\n",
      "in real life, the virtual agent should be able to express different social\n",
      "attitudes. In this paper, we propose a model of social attitudes that enables a\n",
      "virtual agent to reason on the appropriate social attitude to express during\n",
      "the interaction with a user given the course of the interaction, but also the\n",
      "emotions, mood and personality of the agent. Moreover, the model enables the\n",
      "virtual agent to display its social attitude through its non-verbal behaviour.\n",
      "The proposed model has been developed in the context of job interview\n",
      "simulation. The methodology used to develop such a model combined a theoretical\n",
      "and an empirical approach. Indeed, the model is based both on the literature in\n",
      "Human and Social Sciences on social attitudes but also on the analysis of an\n",
      "audiovisual corpus of job interviews and on post-hoc interviews with the\n",
      "recruiters on their expressed attitudes during the job interview.\n",
      "\n",
      "==============================\n",
      "\n",
      "Machine Learning Platforms\n",
      "--------------------------\n",
      "Open science in machine learning , 2014\n",
      "['NL', 'DE', 'AU']\n",
      "We present OpenML and mldata, open science platforms that provides easy\n",
      "access to machine learning data, software and results to encourage further\n",
      "study and application. They go beyond the more traditional repositories for\n",
      "data sets and software packages in that they allow researchers to also easily\n",
      "share the results they obtained in experiments and to compare their solutions\n",
      "with those of others.\n",
      "\n",
      "==============================\n",
      "\n",
      "AI-Optimized Hardware\n",
      "---------------------\n",
      "Hands-on experiments on intelligent behavior for mobile robots , 2014\n",
      "['DE', 'MX']\n",
      "In recent years, Artificial Intelligence techniques have emerged as useful\n",
      "tools for solving various engineering problems that were not possible or\n",
      "convenient to handle by traditional methods. AI has directly influenced many\n",
      "areas of computer science and becomes an important part of the engineering\n",
      "curriculum. However, determining the important topics for a single semester AI\n",
      "course is a nontrivial task, given the lack of a general methodology. AI\n",
      "concepts commonly overlap with many other disciplines involving a wide range of\n",
      "subjects, including applied approaches to more formal mathematical issues. This\n",
      "paper presents the use of a simple robotic platform to assist the learning of\n",
      "basic AI concepts. The study is guided through some simple experiments using\n",
      "autonomous mobile robots. The central algorithm is the Learning Automata. Using\n",
      "LA, each robot action is applied to an environment to be evaluated by means of\n",
      "a fitness value. The response of the environment is used by the automata to\n",
      "select its next action. This procedure holds until the goal task is reached.\n",
      "The proposal addresses the AI study by offering in LA a unifying context to\n",
      "draw together several of the topics of AI and motivating the students to learn\n",
      "by building some hands on laboratory exercises. The presented material has been\n",
      "successfully tested as AI teaching aide in the University of Guadalajara\n",
      "robotics group as it motivates students and increases enrolment and retention\n",
      "while educating better computer engineers.\n",
      "\n",
      "==============================\n",
      "\n",
      "Decision Management AI\n",
      "----------------------\n",
      "Hands-on experiments on intelligent behavior for mobile robots , 2014\n",
      "['DE', 'MX']\n",
      "In recent years, Artificial Intelligence techniques have emerged as useful\n",
      "tools for solving various engineering problems that were not possible or\n",
      "convenient to handle by traditional methods. AI has directly influenced many\n",
      "areas of computer science and becomes an important part of the engineering\n",
      "curriculum. However, determining the important topics for a single semester AI\n",
      "course is a nontrivial task, given the lack of a general methodology. AI\n",
      "concepts commonly overlap with many other disciplines involving a wide range of\n",
      "subjects, including applied approaches to more formal mathematical issues. This\n",
      "paper presents the use of a simple robotic platform to assist the learning of\n",
      "basic AI concepts. The study is guided through some simple experiments using\n",
      "autonomous mobile robots. The central algorithm is the Learning Automata. Using\n",
      "LA, each robot action is applied to an environment to be evaluated by means of\n",
      "a fitness value. The response of the environment is used by the automata to\n",
      "select its next action. This procedure holds until the goal task is reached.\n",
      "The proposal addresses the AI study by offering in LA a unifying context to\n",
      "draw together several of the topics of AI and motivating the students to learn\n",
      "by building some hands on laboratory exercises. The presented material has been\n",
      "successfully tested as AI teaching aide in the University of Guadalajara\n",
      "robotics group as it motivates students and increases enrolment and retention\n",
      "while educating better computer engineers.\n",
      "\n",
      "==============================\n",
      "\n",
      "Deep Learning Platforms\n",
      "-----------------------\n",
      "Caffe: Convolutional Architecture for Fast Feature Embedding , 2014\n",
      "['US', 'CH', 'CA', 'IE', 'GB']\n",
      "Caffe provides multimedia scientists and practitioners with a clean and\n",
      "modifiable framework for state-of-the-art deep learning algorithms and a\n",
      "collection of reference models. The framework is a BSD-licensed C++ library\n",
      "with Python and MATLAB bindings for training and deploying general-purpose\n",
      "convolutional neural networks and other deep models efficiently on commodity\n",
      "architectures. Caffe fits industry and internet-scale media needs by CUDA GPU\n",
      "computation, processing over 40 million images a day on a single K40 or Titan\n",
      "GPU ($\\approx$ 2.5 ms per image). By separating model representation from\n",
      "actual implementation, Caffe allows experimentation and seamless switching\n",
      "among platforms for ease of development and deployment from prototyping\n",
      "machines to cloud environments. Caffe is maintained and developed by the\n",
      "Berkeley Vision and Learning Center (BVLC) with the help of an active community\n",
      "of contributors on GitHub. It powers ongoing research projects, large-scale\n",
      "industrial applications, and startup prototypes in vision, speech, and\n",
      "multimedia.\n",
      "\n",
      "==============================\n",
      "\n",
      "Biometrics AI\n",
      "-------------\n",
      "An Analysis of Random Projections in Cancelable Biometrics , 2014\n",
      "['PL', 'IL', 'JP', 'KR', 'GB', 'CH', 'CN', 'BR', 'DE', 'IN', 'US']\n",
      "With increasing concerns about security, the need for highly secure physical\n",
      "biometrics-based authentication systems utilizing \\emph{cancelable biometric}\n",
      "technologies is on the rise. Because the problem of cancelable template\n",
      "generation deals with the trade-off between template security and matching\n",
      "performance, many state-of-the-art algorithms successful in generating high\n",
      "quality cancelable biometrics all have random projection as one of their early\n",
      "processing steps. This paper therefore presents a formal analysis of why random\n",
      "projections is an essential step in cancelable biometrics. By formally defining\n",
      "the notion of an \\textit{Independent Subspace Structure} for datasets, it can\n",
      "be shown that random projection preserves the subspace structure of data\n",
      "vectors generated from a union of independent linear subspaces. The bound on\n",
      "the minimum number of random vectors required for this to hold is also derived\n",
      "and is shown to depend logarithmically on the number of data samples, not only\n",
      "in independent subspaces but in disjoint subspace settings as well. The\n",
      "theoretical analysis presented is supported in detail with empirical results on\n",
      "real-world face recognition datasets.\n",
      "\n",
      "==============================\n",
      "\n",
      "Robotic Processes Automation AI\n",
      "-------------------------------\n",
      "Hands-on experiments on intelligent behavior for mobile robots , 2014\n",
      "['DE', 'MX']\n",
      "In recent years, Artificial Intelligence techniques have emerged as useful\n",
      "tools for solving various engineering problems that were not possible or\n",
      "convenient to handle by traditional methods. AI has directly influenced many\n",
      "areas of computer science and becomes an important part of the engineering\n",
      "curriculum. However, determining the important topics for a single semester AI\n",
      "course is a nontrivial task, given the lack of a general methodology. AI\n",
      "concepts commonly overlap with many other disciplines involving a wide range of\n",
      "subjects, including applied approaches to more formal mathematical issues. This\n",
      "paper presents the use of a simple robotic platform to assist the learning of\n",
      "basic AI concepts. The study is guided through some simple experiments using\n",
      "autonomous mobile robots. The central algorithm is the Learning Automata. Using\n",
      "LA, each robot action is applied to an environment to be evaluated by means of\n",
      "a fitness value. The response of the environment is used by the automata to\n",
      "select its next action. This procedure holds until the goal task is reached.\n",
      "The proposal addresses the AI study by offering in LA a unifying context to\n",
      "draw together several of the topics of AI and motivating the students to learn\n",
      "by building some hands on laboratory exercises. The presented material has been\n",
      "successfully tested as AI teaching aide in the University of Guadalajara\n",
      "robotics group as it motivates students and increases enrolment and retention\n",
      "while educating better computer engineers.\n",
      "\n",
      "==============================\n",
      "\n",
      "Natural Language Processing\n",
      "---------------------------\n",
      "Linguistic Analysis of Requirements of a Space Project and their\n",
      "  Conformity with the Recommendations Proposed by a Controlled Natural Language , 2014\n",
      "['FR']\n",
      "The long term aim of the project carried out by the French National Space\n",
      "Agency (CNES) is to design a writing guide based on the real and regular\n",
      "writing of requirements. As a first step in the project, this paper proposes a\n",
      "lin-guistic analysis of requirements written in French by CNES engineers. The\n",
      "aim is to determine to what extent they conform to two rules laid down in\n",
      "INCOSE, a recent guide for writing requirements. Although CNES engineers are\n",
      "not obliged to follow any Controlled Natural Language in their writing of\n",
      "requirements, we believe that language regularities are likely to emerge from\n",
      "this task, mainly due to the writers' experience. The issue is approached using\n",
      "natural language processing tools to identify sentences that do not comply with\n",
      "INCOSE rules. We further review these sentences to understand why the\n",
      "recommendations cannot (or should not) always be applied when specifying\n",
      "large-scale projects.\n",
      "\n",
      "==============================\n",
      "\n",
      "Digital Twin AI\n",
      "---------------\n",
      "Hands-on experiments on intelligent behavior for mobile robots , 2014\n",
      "['DE', 'MX']\n",
      "In recent years, Artificial Intelligence techniques have emerged as useful\n",
      "tools for solving various engineering problems that were not possible or\n",
      "convenient to handle by traditional methods. AI has directly influenced many\n",
      "areas of computer science and becomes an important part of the engineering\n",
      "curriculum. However, determining the important topics for a single semester AI\n",
      "course is a nontrivial task, given the lack of a general methodology. AI\n",
      "concepts commonly overlap with many other disciplines involving a wide range of\n",
      "subjects, including applied approaches to more formal mathematical issues. This\n",
      "paper presents the use of a simple robotic platform to assist the learning of\n",
      "basic AI concepts. The study is guided through some simple experiments using\n",
      "autonomous mobile robots. The central algorithm is the Learning Automata. Using\n",
      "LA, each robot action is applied to an environment to be evaluated by means of\n",
      "a fitness value. The response of the environment is used by the automata to\n",
      "select its next action. This procedure holds until the goal task is reached.\n",
      "The proposal addresses the AI study by offering in LA a unifying context to\n",
      "draw together several of the topics of AI and motivating the students to learn\n",
      "by building some hands on laboratory exercises. The presented material has been\n",
      "successfully tested as AI teaching aide in the University of Guadalajara\n",
      "robotics group as it motivates students and increases enrolment and retention\n",
      "while educating better computer engineers.\n",
      "\n",
      "==============================\n",
      "\n",
      "Cyber Defense AI\n",
      "----------------\n",
      "Characterizing the Power of Moving Target Defense via Cyber Epidemic\n",
      "  Dynamics , 2014\n",
      "['US', 'GB']\n",
      "Moving Target Defense (MTD) can enhance the resilience of cyber systems\n",
      "against attacks. Although there have been many MTD techniques, there is no\n",
      "systematic understanding and {\\em quantitative} characterization of the power\n",
      "of MTD. In this paper, we propose to use a cyber epidemic dynamics approach to\n",
      "characterize the power of MTD. We define and investigate two complementary\n",
      "measures that are applicable when the defender aims to deploy MTD to achieve a\n",
      "certain security goal. One measure emphasizes the maximum portion of time\n",
      "during which the system can afford to stay in an undesired configuration (or\n",
      "posture), without considering the cost of deploying MTD. The other measure\n",
      "emphasizes the minimum cost of deploying MTD, while accommodating that the\n",
      "system has to stay in an undesired configuration (or posture) for a given\n",
      "portion of time. Our analytic studies lead to algorithms for optimally\n",
      "deploying MTD.\n",
      "\n",
      "==============================\n",
      "\n",
      "Compliance AI\n",
      "-------------\n",
      "Compliance for reversible client/server interactions , 2014\n",
      "['IT']\n",
      "In the setting of session behaviours, we study an extension of the concept of\n",
      "compliance when a disciplined form of backtracking is present. After adding\n",
      "checkpoints to the syntax of session behaviours, we formalise the operational\n",
      "semantics via a LTS, and define a natural notion of checkpoint compliance. We\n",
      "then obtain a co-inductive characterisation of such compliance relation, and an\n",
      "axiomatic presentation that is proved to be sound and complete. As a byproduct\n",
      "we get a decision procedure for the new compliance, being the axiomatic system\n",
      "algorithmic.\n",
      "\n",
      "==============================\n",
      "\n",
      "Knowledge Worker Aid AI\n",
      "-----------------------\n",
      "Hands-on experiments on intelligent behavior for mobile robots , 2014\n",
      "['DE', 'MX']\n",
      "In recent years, Artificial Intelligence techniques have emerged as useful\n",
      "tools for solving various engineering problems that were not possible or\n",
      "convenient to handle by traditional methods. AI has directly influenced many\n",
      "areas of computer science and becomes an important part of the engineering\n",
      "curriculum. However, determining the important topics for a single semester AI\n",
      "course is a nontrivial task, given the lack of a general methodology. AI\n",
      "concepts commonly overlap with many other disciplines involving a wide range of\n",
      "subjects, including applied approaches to more formal mathematical issues. This\n",
      "paper presents the use of a simple robotic platform to assist the learning of\n",
      "basic AI concepts. The study is guided through some simple experiments using\n",
      "autonomous mobile robots. The central algorithm is the Learning Automata. Using\n",
      "LA, each robot action is applied to an environment to be evaluated by means of\n",
      "a fitness value. The response of the environment is used by the automata to\n",
      "select its next action. This procedure holds until the goal task is reached.\n",
      "The proposal addresses the AI study by offering in LA a unifying context to\n",
      "draw together several of the topics of AI and motivating the students to learn\n",
      "by building some hands on laboratory exercises. The presented material has been\n",
      "successfully tested as AI teaching aide in the University of Guadalajara\n",
      "robotics group as it motivates students and increases enrolment and retention\n",
      "while educating better computer engineers.\n",
      "\n",
      "==============================\n",
      "\n",
      "Content Creation AI\n",
      "-------------------\n",
      "Hands-on experiments on intelligent behavior for mobile robots , 2014\n",
      "['DE', 'MX']\n",
      "In recent years, Artificial Intelligence techniques have emerged as useful\n",
      "tools for solving various engineering problems that were not possible or\n",
      "convenient to handle by traditional methods. AI has directly influenced many\n",
      "areas of computer science and becomes an important part of the engineering\n",
      "curriculum. However, determining the important topics for a single semester AI\n",
      "course is a nontrivial task, given the lack of a general methodology. AI\n",
      "concepts commonly overlap with many other disciplines involving a wide range of\n",
      "subjects, including applied approaches to more formal mathematical issues. This\n",
      "paper presents the use of a simple robotic platform to assist the learning of\n",
      "basic AI concepts. The study is guided through some simple experiments using\n",
      "autonomous mobile robots. The central algorithm is the Learning Automata. Using\n",
      "LA, each robot action is applied to an environment to be evaluated by means of\n",
      "a fitness value. The response of the environment is used by the automata to\n",
      "select its next action. This procedure holds until the goal task is reached.\n",
      "The proposal addresses the AI study by offering in LA a unifying context to\n",
      "draw together several of the topics of AI and motivating the students to learn\n",
      "by building some hands on laboratory exercises. The presented material has been\n",
      "successfully tested as AI teaching aide in the University of Guadalajara\n",
      "robotics group as it motivates students and increases enrolment and retention\n",
      "while educating better computer engineers.\n",
      "\n",
      "==============================\n",
      "\n",
      "Peer to Peer Networks AI\n",
      "------------------------\n",
      "Efficient Cooperative Anycasting for AMI Mesh Networks , 2014\n",
      "['DE', 'FR', 'KR', 'AT', 'JP', 'GB', 'CH', 'US']\n",
      "We have, in recent years, witnessed an increased interest towards enabling a\n",
      "Smart Grid which will be a corner stone to build sustainable energy efficient\n",
      "communities. An integral part of the future Smart Grid will be the\n",
      "communications infrastructure which will make real time control of the grid\n",
      "components possible. Automated Metering Infrastructure (AMI) is thought to be a\n",
      "key enabler for monitoring and controlling the customer loads. %RPL is a\n",
      "connectivity enabling mechanism for low power and lossy networks currently\n",
      "being standardized by the IETF ROLL working group. RPL is deemed to be a\n",
      "suitable candidate for AMI networks where the meters are connected to a\n",
      "concentrator over multi hop low power and lossy links. This paper proposes an\n",
      "efficient cooperative anycasting approach for wireless mesh networks with the\n",
      "aim of achieving reduced traffic and increased utilisation of the network\n",
      "resources. The proposed cooperative anycasting has been realised as an\n",
      "enhancement on top of the Routing Protocol for Low Power and Lossy Networks\n",
      "(RPL), a connectivity enabling mechanism in wireless AMI mesh networks. In this\n",
      "protocol, smart meter nodes utilise an anycasting approach to facilitate\n",
      "efficient transport of metering data to the concentrator node. Moreover, it\n",
      "takes advantage of a distributed approach ensuring scalability.\n",
      "\n",
      "==============================\n",
      "\n",
      "Emotion Recognition AI\n",
      "----------------------\n",
      "STIMONT: A core ontology for multimedia stimuli description , 2014\n",
      "['HR']\n",
      "Affective multimedia documents such as images, sounds or videos elicit\n",
      "emotional responses in exposed human subjects. These stimuli are stored in\n",
      "affective multimedia databases and successfully used for a wide variety of\n",
      "research in psychology and neuroscience in areas related to attention and\n",
      "emotion processing. Although important all affective multimedia databases have\n",
      "numerous deficiencies which impair their applicability. These problems, which\n",
      "are brought forward in the paper, result in low recall and precision of\n",
      "multimedia stimuli retrieval which makes creating emotion elicitation\n",
      "procedures difficult and labor-intensive. To address these issues a new core\n",
      "ontology STIMONT is introduced. The STIMONT is written in OWL-DL formalism and\n",
      "extends W3C EmotionML format with an expressive and formal representation of\n",
      "affective concepts, high-level semantics, stimuli document metadata and the\n",
      "elicited physiology. The advantages of ontology in description of affective\n",
      "multimedia stimuli are demonstrated in a document retrieval experiment and\n",
      "compared against contemporary keyword-based querying methods. Also, a software\n",
      "tool Intelligent Stimulus Generator for retrieval of affective multimedia and\n",
      "construction of stimuli sequences is presented.\n",
      "\n",
      "==============================\n",
      "\n",
      "Image Recognition AI\n",
      "--------------------\n",
      "Hands-on experiments on intelligent behavior for mobile robots , 2014\n",
      "['DE', 'MX']\n",
      "In recent years, Artificial Intelligence techniques have emerged as useful\n",
      "tools for solving various engineering problems that were not possible or\n",
      "convenient to handle by traditional methods. AI has directly influenced many\n",
      "areas of computer science and becomes an important part of the engineering\n",
      "curriculum. However, determining the important topics for a single semester AI\n",
      "course is a nontrivial task, given the lack of a general methodology. AI\n",
      "concepts commonly overlap with many other disciplines involving a wide range of\n",
      "subjects, including applied approaches to more formal mathematical issues. This\n",
      "paper presents the use of a simple robotic platform to assist the learning of\n",
      "basic AI concepts. The study is guided through some simple experiments using\n",
      "autonomous mobile robots. The central algorithm is the Learning Automata. Using\n",
      "LA, each robot action is applied to an environment to be evaluated by means of\n",
      "a fitness value. The response of the environment is used by the automata to\n",
      "select its next action. This procedure holds until the goal task is reached.\n",
      "The proposal addresses the AI study by offering in LA a unifying context to\n",
      "draw together several of the topics of AI and motivating the students to learn\n",
      "by building some hands on laboratory exercises. The presented material has been\n",
      "successfully tested as AI teaching aide in the University of Guadalajara\n",
      "robotics group as it motivates students and increases enrolment and retention\n",
      "while educating better computer engineers.\n",
      "\n",
      "==============================\n",
      "\n",
      "Marketing Automation AI\n",
      "-----------------------\n",
      "Hands-on experiments on intelligent behavior for mobile robots , 2014\n",
      "['DE', 'MX']\n",
      "In recent years, Artificial Intelligence techniques have emerged as useful\n",
      "tools for solving various engineering problems that were not possible or\n",
      "convenient to handle by traditional methods. AI has directly influenced many\n",
      "areas of computer science and becomes an important part of the engineering\n",
      "curriculum. However, determining the important topics for a single semester AI\n",
      "course is a nontrivial task, given the lack of a general methodology. AI\n",
      "concepts commonly overlap with many other disciplines involving a wide range of\n",
      "subjects, including applied approaches to more formal mathematical issues. This\n",
      "paper presents the use of a simple robotic platform to assist the learning of\n",
      "basic AI concepts. The study is guided through some simple experiments using\n",
      "autonomous mobile robots. The central algorithm is the Learning Automata. Using\n",
      "LA, each robot action is applied to an environment to be evaluated by means of\n",
      "a fitness value. The response of the environment is used by the automata to\n",
      "select its next action. This procedure holds until the goal task is reached.\n",
      "The proposal addresses the AI study by offering in LA a unifying context to\n",
      "draw together several of the topics of AI and motivating the students to learn\n",
      "by building some hands on laboratory exercises. The presented material has been\n",
      "successfully tested as AI teaching aide in the University of Guadalajara\n",
      "robotics group as it motivates students and increases enrolment and retention\n",
      "while educating better computer engineers.\n",
      "\n",
      "==============================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for term in [\"Natural Language Generation\",\n",
    "             \"Speech recognition\",\n",
    "             \"Virtual Agents\",\n",
    "             \"Machine Learning Platforms\",\n",
    "             \"AI-Optimized Hardware\",\n",
    "             \"Decision Management AI\",\n",
    "             \"Deep Learning Platforms\",\n",
    "             \"Biometrics AI\",\n",
    "             \"Robotic Processes Automation AI\",\n",
    "             \"Natural Language Processing\",\n",
    "             \"Digital Twin AI\",\n",
    "             \"Cyber Defense AI\",\n",
    "             \"Compliance AI\", \n",
    "             \"Knowledge Worker Aid AI\",\n",
    "             \"Content Creation AI\",\n",
    "             \"Peer to Peer Networks AI\",\n",
    "             \"Emotion Recognition AI\",\n",
    "             \"Image Recognition AI\",\n",
    "             \"Marketing Automation AI\"]:\n",
    "    print(term)\n",
    "    print(\"-\"*len(term))\n",
    "    top_doc, data, all_scores = generate_indicator(term)\n",
    "    print(top_doc['title_of_article'], \",\", top_doc['year_of_article'])\n",
    "    print(top_doc['terms_countries_article'])\n",
    "    print(top_doc['textBody_abstract_article'])\n",
    "    print(\"\\n==============================\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
