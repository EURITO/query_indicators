{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath('../../'))\n",
    "from query_indicators import generate_save_path\n",
    "from query_indicators import get_eu_countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from collections import defaultdict\n",
    "from clio_lite import clio_search, clio_search_iter\n",
    "import io\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.collections import PatchCollection\n",
    "from matplotlib.patches import Rectangle\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Env variables\n",
    "mpl.rcParams['hatch.linewidth'] = 0.2\n",
    "mpl.rcParams['font.size'] = 18\n",
    "mpl.rcParams['image.cmap'] = 'Pastel1'\n",
    "os.environ['AWS_SHARED_CREDENTIALS_FILE'] = '/Users/jklinger/EURITO-AWS/.aws/credentials'  # <--- Note: NOT nesta's AWS credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some globals\n",
    "URL = \"https://search-eurito-dev-vq22tw6otqjpdh47u75bh2g7ba.eu-west-2.es.amazonaws.com/\"\n",
    "INDEX = \"arxiv_v0\" \n",
    "FIELDS = ['terms_tokens_entity', 'textBody_abstract_article']\n",
    "EU_COUNTRIES = get_eu_countries()\n",
    "COLORS = plt.get_cmap('Set2').colors\n",
    "COLOR_MAP = 'Pastel1'\n",
    "S3 = boto3.resource('s3')\n",
    "SAVE_PATH = generate_save_path()  # EURITO collaborators: this is generated assuming you have stuck to the convention 'theme_x/something/something_else.ipynb'\n",
    "BUCKET = 'eurito-indicators'  # EURITO collaborators: please don't change this\n",
    "SAVE_RESULTS = True  # Set this to \"False\" when you want to view figures inline. When \"True\", results will be saved to S3.\n",
    "\n",
    "if SAVE_RESULTS:\n",
    "    plt.ioff()  # <--- for turning off visible figs\n",
    "else:\n",
    "    plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_search(query, max_query_terms, yr0=2014, yr1=2019, countries=EU_COUNTRIES, window=1):\n",
    "    \"\"\"\n",
    "    Retrieve count and score data for a given basic clio search.\n",
    "    \n",
    "    Args:\n",
    "        query (str): Seed query for clio.\n",
    "        max_query_terms (list): Triple of max_query_terms (low, middle, high) to use from the initial query.\n",
    "        yr0 (int): Start year in range to use in filter.\n",
    "        yr1 (int): Final year in range to use in filter.\n",
    "        countries (list): A list of countries to filter (default to all EU).\n",
    "        window (int): The number of years to consider in between time windows. Note that changing this will lead to double-counting.\n",
    "    Returns:\n",
    "        data (dict): {max_query_terms --> [{year --> sum_score} for each country]}\n",
    "        all_scores (dict): {max_query_terms --> {country --> [score for doc in docs] } }\n",
    "    \"\"\"\n",
    "    top_doc = None\n",
    "    _data = defaultdict(lambda: defaultdict(dict))  # {max_query_terms --> {year --> {country --> score} } }\n",
    "    all_scores = defaultdict(lambda: defaultdict(list))  # {max_query_terms --> {country --> [score for doc in docs] } }\n",
    "    for n in max_query_terms:\n",
    "        # Set the order of the countries\n",
    "        for ctry in EU_COUNTRIES:\n",
    "            _data[n][ctry]\n",
    "            all_scores[n][ctry]\n",
    "        # Iterate over years\n",
    "        for yr in range(yr0, yr1+1):\n",
    "            # Set default values for countries\n",
    "            for ctry in EU_COUNTRIES:\n",
    "                _data[n][ctry][yr] = 0            \n",
    "            # Iterate over docs\n",
    "            filters = [{\"range\":{\"year_of_article\":{\"gte\":yr, \"lt\":yr+window}}}]\n",
    "            for doc in clio_search_iter(url=URL, index=INDEX, query=query, fields=FIELDS,\n",
    "                                        max_query_terms=n, post_filters=filters, chunksize=5000):\n",
    "                if '_score' not in doc or doc['terms_countries_article'] is None:\n",
    "                    continue\n",
    "                score = doc['_score']\n",
    "                for ctry in filter(lambda x: x in countries, doc['terms_countries_article']):\n",
    "                    if top_doc is None:\n",
    "                        top_doc = doc                \n",
    "                    all_scores[n][ctry].append(score)\n",
    "                    _data[n][ctry][yr] += score\n",
    "    # Reformat data as {max_query_terms --> [{year --> score} for each country in order]}\n",
    "    data = {}\n",
    "    for n, ctry_data in _data.items():\n",
    "        data[n] = []\n",
    "        for ctry, yr_data in ctry_data.items():\n",
    "            data[n].append(yr_data)\n",
    "    return top_doc, data, all_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indicator calculations\n",
    "\n",
    "Each of these functions is assumed to take the form\n",
    "\n",
    "```python\n",
    "def _an_indicator_calulation(data, year=None, _max=1):\n",
    "    \"\"\"\n",
    "    A function calculating an indicator.\n",
    "    \n",
    "    Args:\n",
    "        data (list): Rows of data\n",
    "        year (int): A year to consider, if applicable.\n",
    "        _max (int): Divide by this to normalise your results. This is automatically applied in :obj:`make_activity_plot`\n",
    "    Returns:\n",
    "        result (list) A list of indicators to plot. The length of the list is assumed to be equal to the number of countries.\n",
    "    \"\"\"\n",
    "    # Calculate something\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _total_activity_by_country(data, year=None, _max=1):\n",
    "    \"\"\"\n",
    "    Indicator: Sum of relevance scores, by year (if specified) or in total.\n",
    "    \"\"\"    \n",
    "    if year is None:        \n",
    "        scores = [sum(row.values())/_max for row in data]\n",
    "    else:\n",
    "        scores = [row[year]/_max for row in data]\n",
    "    return scores\n",
    "      \n",
    "\n",
    "def _average_activity_by_country(data, year=None, _max=1):    \n",
    "    \"\"\"\n",
    "    Indicator: Mean relevance score. This function is basically a lambda, since it assumes the average has already been calculated.\n",
    "    \"\"\"        \n",
    "    return [row/_max for row in data]\n",
    "    \n",
    "    \n",
    "def _corrected_average_activity_by_country(data, year=None, _max=1):\n",
    "    \"\"\"\n",
    "    Indicator: Mean relevance score minus it's (very) approximate Poisson error.\n",
    "    \"\"\"    \n",
    "    return [(row - np.sqrt(row))/_max for row in data]\n",
    "    \n",
    "\n",
    "def _linear_coeffs(years, scores, _max):\n",
    "    \"\"\"Calculates linear coefficients for scores wrt years\"\"\"\n",
    "    return [np.polyfit(_scores, _years, 1)[0]/_max\n",
    "            if all(v > 0 for v in _scores) else 0\n",
    "            for _years, _scores in zip(years, scores)]    \n",
    "    \n",
    "\n",
    "def _trajectory(data, year=None, _max=1):\n",
    "    \"\"\"\n",
    "    Indicator: Linear coefficient of total relevance score wrt year\n",
    "    \"\"\"\n",
    "    years = [list(row.keys()) for row in data]\n",
    "    scores = [list(row.values()) for row in data]\n",
    "    return _linear_coeffs(years, scores, _max)\n",
    "\n",
    "\n",
    "def _corrected_trajectory(data, year=None, _max=1):\n",
    "    \"\"\"\n",
    "    Indicator: Linear coefficient of upper and lower limits of relevance score wrt year\n",
    "    \"\"\" \n",
    "    # Reformulate the data in terms of upper and lower bounds\n",
    "    years, scores = [], []\n",
    "    for row in data:\n",
    "        _years, _scores = [], []\n",
    "        for k, v in row.items():\n",
    "            _years += [k,k]\n",
    "            _scores += [v - np.sqrt(v), v + np.sqrt(v)]  # Estimate upper and lower limits with very approximate Poisson errors\n",
    "        years.append(_years)\n",
    "        scores.append(_scores)\n",
    "    return _linear_coeffs(years, scores, _max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _Sorter:\n",
    "    def __init__(self, values, topn=None):\n",
    "        if topn is None:\n",
    "            topn = len(values)\n",
    "        self.indices = list(np.argsort(values))[-topn:]  # Argsort is ascending, so -ve indexing to pick up topn\n",
    "    def sort(self, x):\n",
    "        \"\"\"Sort list x by indices\"\"\"\n",
    "        return [x[i] for i in self.indices]\n",
    "\n",
    "\n",
    "def _s3_savefig(query, fig_name, extension='png'):\n",
    "    \"\"\"Save the figure to s3. The figure is grabbed from the global scope.\"\"\"\n",
    "    if not SAVE_RESULTS:\n",
    "        return    \n",
    "    outname = (f'figures/{SAVE_PATH}/'\n",
    "               f'{query.replace(\" \",\"_\").lower()}'\n",
    "               f'/{fig_name.replace(\" \",\"_\").lower()}'\n",
    "               f'.{extension}')\n",
    "    with io.BytesIO() as f:\n",
    "        plt.savefig(f, bbox_inches='tight', format=extension, pad_inches=0)\n",
    "        obj = S3.Object(BUCKET, outname)\n",
    "        f.seek(0)\n",
    "        obj.put(Body=f)\n",
    "\n",
    "        \n",
    "def _s3_savetable(data, key, index, object_path, transformer=lambda x: x):\n",
    "    \"\"\"Upload the table to s3\"\"\"\n",
    "    if not SAVE_RESULTS:\n",
    "        return\n",
    "    df = pd.DataFrame(transformer(data[key]), index=index)\n",
    "    if len(df.columns) == 1:\n",
    "        df.columns = ['value']\n",
    "    df = df / df.max().max()\n",
    "    table_data = df.to_csv().encode()\n",
    "    obj = S3.Object(BUCKET, os.path.join(f'tables/{SAVE_PATH}', object_path))\n",
    "    obj.put(Body=table_data)\n",
    "\n",
    "        \n",
    "def make_activity_plot(f, data, countries, max_query_terms, query, \n",
    "                       year=None, label=None, x_padding=0.5, y_padding=0.05, xlabel_fontsize=14):\n",
    "    \"\"\"\n",
    "    Make a query and generate indicators by country, saving the plots to S3 and saving the rawest data\n",
    "    to tables on S3.\n",
    "    \n",
    "    \n",
    "    Args:\n",
    "        f: An indicator function, as described in the 'Indicator calculations' section.\n",
    "        data (dict): {max_query_terms --> [{year --> sum_score} for each country]}\n",
    "        countries (list): A list of EU ISO-2 codes        \n",
    "        max_query_terms (list): Triple of max_query_terms for clio, corresponding to low, middle and high values of \n",
    "                                max_query_terms to test robustness of the query.\n",
    "        query (str): query used to generate this data.\n",
    "        year (int): Year to generate the indicator for (if applicable).\n",
    "        label (str): label for annotating the plot.\n",
    "        {x,y}_padding (float): Aesthetic padding around the extreme limits of the {x,y} axis.\n",
    "        xlabel_fontsize (int): Fontsize of the x labels (country ISO-2 codes).\n",
    "    \"\"\"    \n",
    "    # Calculate the indicator for each value of n, then recalculate the normalised indicator\n",
    "    _, middle, _ = (f(data[n], year=year) for n in max_query_terms)\n",
    "    low, middle, high = (f(data[n], year=year, _max=max(middle)) for n in max_query_terms)\n",
    "    indicator = [np.median([a, b, c]) for a, b, c in zip(low, middle, high)]    \n",
    "\n",
    "    # Sort all data by indicator value\n",
    "    s = _Sorter(indicator)\n",
    "    countries = s.sort(countries)\n",
    "    low = s.sort(low)\n",
    "    middle = s.sort(middle)\n",
    "    high =  s.sort(high)\n",
    "    indicator = s.sort(indicator)\n",
    "\n",
    "    # Make the scatter plot\n",
    "    fig, ax = plt.subplots(figsize=(15, 6))    \n",
    "    make_error_boxes(ax, low, middle, high)  # Draw the bounding box\n",
    "    ax.scatter(countries, indicator,  s=0, marker='o', color='black')  # Draw the centre mark\n",
    "    ax.set_title(f'{label}\\nQuery: \"{query}\"')\n",
    "    ax.set_ylabel(label)\n",
    "\n",
    "    # Set limits and formulate \n",
    "    y0 = min(low+middle+high)    \n",
    "    y1 = max(low+middle+high)\n",
    "    if -y1*y_padding < y0:\n",
    "        y0 = -y1*y_padding\n",
    "    else:  # In case of negative values\n",
    "        y0 = y0 - np.abs(y0*y_padding)\n",
    "    ax.set_ylim(y0, y1*(1+y_padding))\n",
    "    ax.set_xlim(-x_padding, len(countries)-x_padding)\n",
    "    for tick in ax.xaxis.get_major_ticks():\n",
    "        tick.label.set_fontsize(xlabel_fontsize)\n",
    "    \n",
    "    # Save to s3 & return\n",
    "    _s3_savefig(query, label)\n",
    "    return ax\n",
    "\n",
    "\n",
    "def make_error_boxes(ax, low, middle, high, facecolor='r',\n",
    "                     edgecolor='None', alpha=0.5):\n",
    "    \"\"\"\n",
    "    Generate outer rectangles based on three values, and draw a horizontal line through the middle of the rectangle.\n",
    "    No assumption is made on the order of values, so don't worry if they're not properly ordered.\n",
    "        \n",
    "    Args:\n",
    "        ax (matplotlib.axis): An axis to add patches to.\n",
    "        {low, middle, high} (list): Three concurrent lists of values from which to calculate the rectangle limits.\n",
    "        {facecolor, edgecolor} (str): The {face,edge} colour of the rectangles.\n",
    "        alpha (float): The alpha of the rectangles.\n",
    "    \"\"\"\n",
    "    # Generate the rectangle\n",
    "    errorboxes = []\n",
    "    middlelines = []\n",
    "    for x, ys in enumerate(zip(low, middle, high)):        \n",
    "        rect = Rectangle((x - 0.45, min(ys)), 0.9, max(ys) - min(ys))\n",
    "        line = Rectangle((x - 0.45, np.median(ys)), 0.9, 0)\n",
    "        errorboxes.append(rect)\n",
    "        middlelines.append(line)\n",
    "\n",
    "    # Create patch collection with specified colour/alpha\n",
    "    pc = PatchCollection(errorboxes, facecolor=facecolor, alpha=alpha, edgecolor=edgecolor, hatch='/')\n",
    "    lc = PatchCollection(middlelines, facecolor='black', alpha=0.9, edgecolor='black')\n",
    "\n",
    "    # Add collection to axes\n",
    "    ax.add_collection(pc)\n",
    "    ax.add_collection(lc)\n",
    "\n",
    "\n",
    "def stacked_scores(all_scores, query, topn=8,\n",
    "                   low_bins=[10**i for i in np.arange(0, 1.1, 0.025)],\n",
    "                   high_bins=[10**i for i in np.arange(1.1, 2.5, 0.05)],\n",
    "                   x_scale='log', label='Relevance score breakdown', \n",
    "                   xlabel='Relevance score', ylabel='Number of relevant documents',\n",
    "                   legend_fontsize='small', legend_cols=2):\n",
    "    \"\"\"\n",
    "    Create stacked histogram of document scores by country. Two sets of bins are used, \n",
    "    in order to have a more legible binning scale.\n",
    "    \n",
    "    Args:\n",
    "        all_scores (dict): {max_query_terms --> {country --> [score for doc in docs] } }\n",
    "        query (str): query used to generate this data.\n",
    "        low_bins (list): List of initial bin edges.\n",
    "        high_bins (list): List of supplementary bin edges. These could have a different spacing scheme to the lower bin edges.\n",
    "        x_scale (str): Argument for `ax.set_xscale`.\n",
    "        label (str): label for annotating the plot.\n",
    "        {x,y}_label (str): Argument for `ax.set_{x,y}label`.\n",
    "        legend_fontsize (str): Argument for legend fontsize.\n",
    "        legend_cols (str): Argument for legend ncol.        \n",
    "    \"\"\"\n",
    "    \n",
    "    # Sort countries and scores by the sum of scores by country\n",
    "    countries = list(all_scores.keys())\n",
    "    scores = list(all_scores.values())    \n",
    "    s = _Sorter([sum(v) for v in scores], topn=topn)\n",
    "    scores = s.sort(scores)\n",
    "    countries = s.sort(countries)\n",
    "\n",
    "    # Plot the stacked scores\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    plt.set_cmap(COLOR_MAP)\n",
    "    ax.hist(scores, bins=low_bins+high_bins, stacked=True,\n",
    "            label=countries, color=COLORS[:len(scores)])\n",
    "    \n",
    "    # Prettify the plot\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.legend(fontsize=legend_fontsize, ncol=legend_cols)\n",
    "    ax.set_xlim(low_bins[0], None)\n",
    "    ax.set_xscale(x_scale)\n",
    "    ax.set_title(f'{label}\\nQuery: \"{query}\"')\n",
    "    \n",
    "    # Save to s3\n",
    "    _s3_savefig(query, label)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bringing it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_indicator(q, max_query_terms=[7, 10, 13], countries=EU_COUNTRIES, *args, **kwargs):\n",
    "    \"\"\"\n",
    "    Make a query and generate indicators by country, saving the plots to S3 and saving the rawest data\n",
    "    to tables on S3.\n",
    "    \n",
    "    \n",
    "    Args:\n",
    "        q (str): The query to Elasticsearch\n",
    "        max_query_terms (list): Triple of max_query_terms for clio, corresponding to low, middle and high values of \n",
    "                                max_query_terms to test robustness of the query.\n",
    "        countries (list): A list of EU ISO-2 codes\n",
    "    Returns:\n",
    "        top_doc (dict): The highest ranking document from the search.\n",
    "        data (dict): {max_query_terms --> [{year --> sum_score} for each country]}\n",
    "        all_scores (dict): {max_query_terms --> {country --> [score for doc in docs] } }\n",
    "    \"\"\"\n",
    "    \n",
    "    # Make the search and retrieve scores by country, and the highest ranking doc\n",
    "    example_doc, data, all_scores = make_search(q, max_query_terms=max_query_terms, countries=countries, *args, **kwargs)\n",
    "\n",
    "    # Reformat the scores to calculate the average\n",
    "    avg_scores = defaultdict(list)\n",
    "    for ctry in countries:\n",
    "        for n, _scores in all_scores.items():\n",
    "            mean = np.mean(_scores[ctry]) if len(_scores[ctry]) > 0 else 0\n",
    "            avg_scores[n].append(mean)\n",
    "    \n",
    "    plot_kwargs = dict(countries=countries, max_query_terms=max_query_terms, query=q)\n",
    "    # Calculate loads of indicators and save the plots\n",
    "    _ = make_activity_plot(_total_activity_by_country, data, label='Total relevance score', **plot_kwargs)\n",
    "    _ = make_activity_plot(_average_activity_by_country, avg_scores, label='Average relevance', **plot_kwargs)\n",
    "    _ = make_activity_plot(_corrected_average_activity_by_country, avg_scores, label='Corrected average relevance',  **plot_kwargs)\n",
    "    _ = make_activity_plot(_trajectory, data, label='Trajectory', **plot_kwargs)\n",
    "    _ = make_activity_plot(_corrected_trajectory, data, label='Corrected trajectory', **plot_kwargs)\n",
    "    _ = stacked_scores(all_scores[max_query_terms[1]], query=q)\n",
    "    \n",
    "    # Save the basic raw data as tables. Note: not as rich as the plotted data.\n",
    "    _s3_savetable(data, max_query_terms[1], index=countries, object_path='total_relevance.csv')\n",
    "    _s3_savetable(avg_scores, max_query_terms[1], index=countries, object_path='avg_relevance.csv')\n",
    "    _s3_savetable(data, max_query_terms[1], transformer=_trajectory, index=countries, \n",
    "                  object_path='trajectory.csv')\n",
    "    \n",
    "    plt.close('all')  # Clean up the memory cache (unbelievable that matplotlib doesn't do this)\n",
    "    return example_doc, data, all_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterate over queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for term in [\"Natural Language Generation\",\n",
    "             \"Speech recognition\",\n",
    "             \"Virtual Agents\",\n",
    "             \"Machine Learning Platforms\",\n",
    "             \"AI-Optimized Hardware\",\n",
    "             \"Decision Management\",\n",
    "             \"Deep Learning Platforms\",\n",
    "             \"Biometrics\",\n",
    "             \"Robotic Processes Automation\",\n",
    "             \"Natural Language Processing\",\n",
    "             \"Digital Twin\",\n",
    "             \"Cyber Defense\",\n",
    "             \"Compliance\", \n",
    "             \"Knowledge Worker Aid\",\n",
    "             \"Content Creation\",\n",
    "             \"Peer to Peer Networks\",\n",
    "             \"Emotion Recognition\",\n",
    "             \"Image Recognition\",\n",
    "             \"Marketing Automation\"]:\n",
    "    print(term)\n",
    "    print(\"-\"*len(term))\n",
    "    top_doc, data, all_scores = generate_indicator(term)\n",
    "    print(top_doc['title_of_article'], \",\", top_doc['year_of_article'])\n",
    "    print(top_doc['terms_countries_article'])\n",
    "    print(top_doc['textBody_abstract_article'])\n",
    "    print(\"\\n==============================\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
